{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05e5cc6095a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# Загрузка библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import combinations\n",
    "from statsmodels.stats import weightstats \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress:\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import silhouette_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фиксация random seed для воспроизводимости экспериментов\n",
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фиксация версии пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных в переменные\n",
    "train = pd.read_csv('main_task.csv')\n",
    "valid = pd.read_csv('kaggle_task.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Объединяем данные, помячая тренировочные\n",
    "train['train'] = 1\n",
    "valid['train'] = 0\n",
    "valid['Rating'] = 0.\n",
    "data = train.append(valid, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первичный взгляд на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание полей\n",
    "\n",
    "- Restaurant_id - ID\n",
    "- City - Город \n",
    "- Cuisine Style - Кухня\n",
    "- Ranking - Ранг ресторана относительно других ресторанов в этом городе\n",
    "- Price Range - Цены в ресторане в 3 категориях\n",
    "- Number of Reviews - Количество отзывов\n",
    "- Reviews - 2 последних отзыва и даты этих отзывов\n",
    "- URL_TA - Cтраница ресторана на 'www.tripadvisor.com' \n",
    "- ID_TA - ID ресторана в TripAdvisor\n",
    "- Rating - Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бросается в глаза, признаки 'Cuisine Style' и 'Reviews' являют списками. В частности, в 'Reviews' есть даты. Для корректной работы необходимо извлечь из них полезную иформацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращяет визуализацию и относительную долю пропусков в данных\n",
    "def na_values(df):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(df.isnull(),\n",
    "                yticklabels=False, \n",
    "                cbar=False,\n",
    "                cmap='viridis')\n",
    "    plt.show()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        value = df[column].isna().sum()\n",
    "        if value > 0:\n",
    "            print(column.upper())\n",
    "            print('%% пропущенных данных в столбце: \\t{}'.format(np.round(value/len(df[column])*100), 2))\n",
    "            print('(%% от общего кол-ва данных: \\t{})'.format(np.round(value/np.product(df.shape)*100), 2))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более трети строк содержит пропуски. Перед тем как приступать к моделированию, будет необходимо их заполнить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID дубликаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется три признака, которые должны быть уникальны для каждого ресторана:\n",
    "\n",
    "    - 'Restaurant_id'\n",
    "    - 'URL_TA'\n",
    "    - 'ID_TA'\n",
    "Имеет смысл проверить уникальность и удалить неинформативные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает %% уникальных зачений для выбранных признаков\n",
    "def unique_id_check(df, cols):\n",
    "    for col in cols:\n",
    "        print(col.upper())\n",
    "        print('%% уникальных значений в столбце: \\t{}'.format(np.round(len(df[col].unique())/df.shape[0]*100, 2)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_check(train, ['Restaurant_id','URL_TA','ID_TA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения не уникальны для всех трех признаков. Имеет смысл проверить, одинаковы ли дубликаты для 'URL_TA' и 'ID_TA'. И разобраться почему 'Restaurant_id' уникально меньше, чем для трети ресторанов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фунция возвращает дупликаты для наиболее уникального признака из списка\n",
    "def cross_duplicates(df, cols):\n",
    "    max_value = 0\n",
    "    for col in cols:\n",
    "        if len(train[col].unique()) >= max_value:\n",
    "            max_value = len(train[col].unique())\n",
    "            base = col\n",
    "    cols.remove(base)\n",
    "    dups = df[df[base].duplicated() == True][base].values\n",
    "    \n",
    "    for col in cols:\n",
    "        count = 0\n",
    "        for i in dups:\n",
    "            if len(df[df[base] == i][col].unique()) > 1:\n",
    "                print('Несколько значений {} для {} = {}'.format(col.upper(), \n",
    "                                                                 base.upper(), i))\n",
    "                count += 1\n",
    "        if count == 0:\n",
    "            print('Значения {} уникальны для каждого {}'.format(col.upper(), base.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_duplicates(train, ['Restaurant_id','URL_TA','ID_TA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки 'URL_TA' и 'ID_TA'  дублируют друг друга. Что касается 'Restaurant_id', необходимо рассмотреть случаи, когда для 'ID_TA' данный признак разный и наоборот."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример, когда для одного 'ID_TA' несколько 'Restaurant_id'\n",
    "train[train.ID_TA=='d4600226']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разброс рейтинга для одинаковых 'ID_TA'\n",
    "idd = train[train['ID_TA'].duplicated() == True]\n",
    "idd = pd.concat([idd, train[train['ID_TA'].duplicated(keep='last') == True]])\n",
    "(idd.groupby('ID_TA').Rating.max() - \n",
    " idd.groupby('ID_TA').Rating.min()).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример, когда для одного 'Restaurant_id' при нескольких 'ID_TA' и 'URL_TA'\n",
    "# Для удобства выведены первые 5 примеров и ссылок\n",
    "r_id_dups = train[train['Restaurant_id'].duplicated() == True]['Restaurant_id'].unique()\n",
    "example = train[train['Restaurant_id'] == r_id_dups[0]].URL_TA.values\n",
    "display(train[train['Restaurant_id'] == r_id_dups[0]].head(5))\n",
    "example[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML - запрос на tripadvisor.com, вывод заголовков страниц\n",
    "for i in range(5):\n",
    "    url = 'https://www.tripadvisor.com'+example[i]\n",
    "    response = requests.get(url)\n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    print(page.find('h1').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разброс рейтинга для одинаковых 'Restaurant_id'\n",
    "rid = train[train['Restaurant_id'].duplicated() == True]\n",
    "rid = pd.concat([rid, train[train['Restaurant_id'].duplicated(keep='last') == True]])\n",
    "(rid.groupby('Restaurant_id').Rating.max() - \n",
    " rid.groupby('Restaurant_id').Rating.min()).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка сколько Restaurant_id встречаются более одного раза в sample_submission\n",
    "sum(sample_submission.Restaurant_id.value_counts()>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка сколько Restaurant_id встречаются более одного раза в валидационных данных\n",
    "sum(data[data.train==0].Restaurant_id.value_counts()>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий 'Restaurant_id' бывает у ресторанов с разными названиями, из разных городов, с разной кухней. Разброс целевой переменной для уникального 'Restaurant_id' равен 0 только в 28% случаев и можен достигать 4. Разные 'Restaurant_id' для одного 'ID_TA' не несут ценности, т.к. в этом случае разброс целевой переменной равен 0.\n",
    "\n",
    "Тем не менее, необходимо сохранить переменную для выгрузки финального результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Удаление\n",
    "\n",
    "- Удаление дубликатов по 'ID_TA'\n",
    "- Удаление 'URL_TA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates('ID_TA')\n",
    "data = train.append(valid, sort=False).reset_index(drop=True)\n",
    "\n",
    "data.drop('URL_TA', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обработка Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пометка данных имеющих пропуски\n",
    "data['cuisine_nan'] = pd.isna(data['Cuisine Style']).astype('uint8')\n",
    "\n",
    "# Создание списка из строки\n",
    "data['Cuisine Style'] = data['Cuisine Style'].str.findall(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает кол-во кухонь в списке и 0 для NaN\n",
    "def counter(cuisine_list):\n",
    "    try:\n",
    "        return len(cuisine_list)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cuisine_amount'] = data['Cuisine Style'].apply(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обработка Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уникальные значения\n",
    "pr_u = data['Price Range'].unique()\n",
    "pr_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словоря для преобразования класса цены в число\n",
    "mapping_dict = {pr_u[0]: 2,\n",
    "                pr_u[2]: 3,\n",
    "                pr_u[3]: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пометка данных имеющих пропуски\n",
    "data['p_range_nan'] = pd.isna(data['Price Range']).astype('uint8')\n",
    "\n",
    "# Преобразование признака в числовой формат\n",
    "data['Price Range'] = data['Price Range'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обработка Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски\n",
    "data[data.Reviews.isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропусков всего 2, можно заполнить самым популярным значением (пустым списом)\n",
    "data.Reviews.fillna(data.Reviews.value_counts().index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция преобразования списка строковых дат в формат datetime\n",
    "def str_list_to_date(d_list):\n",
    "    result = []\n",
    "    for date in d_list:\n",
    "        result.append(pd.to_datetime(date, infer_datetime_format=True))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение списка дат из Reviews\n",
    "data['review_dates'] = data.Reviews.str.findall(r'\\d+/\\d+/\\d+')\n",
    "data.review_dates = data.review_dates.apply(str_list_to_date)\n",
    "\n",
    "# Извлечение списка слов из Reviews\n",
    "data['wordbox'] = data.Reviews.str.lower()\n",
    "data.wordbox = data.wordbox.str.findall(r'\\w[a-z]+')\n",
    "\n",
    "# Удаление исходного столбца\n",
    "data.drop('Reviews', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Даты\n",
    "\n",
    "Извлекаем кол-во отзывов, время между отзывами, время последнего отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кол-во отзывов\n",
    "data['rvws_amount'] = data.review_dates.apply(lambda x: len(x))\n",
    "data.rvws_amount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фунция возвращает разницу между превым и последним отзывом\n",
    "def review_t_dif(cell):\n",
    "    if len(cell)>=2:\n",
    "        dif=max(cell)-min(cell)\n",
    "        return dif.total_seconds()\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rvws_time_span'] = data.review_dates.apply(review_t_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фунция возвращает разницу между превым и последним отзывом\n",
    "def review_latest(cell):\n",
    "    if len(cell)>=1:\n",
    "        return max(cell).timestamp()\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rvws_latest'] = data.review_dates.apply(review_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление списка дат\n",
    "data.drop('review_dates', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Текст\n",
    "\n",
    "Кластеризация коментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель преобразования слов в вектора\n",
    "word_model = Word2Vec(data.wordbox, min_count=5, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает усредненный вектор документа на основе векторов слов\n",
    "def doc_vectorizer(doc, model=word_model):\n",
    "    doc_vector = []\n",
    "    num_words = 0\n",
    "    for word in doc:\n",
    "        try:\n",
    "            if num_words == 0:\n",
    "                doc_vector = model[word]\n",
    "            else:\n",
    "                doc_vector = np.add(doc_vector, model[word])\n",
    "            num_words += 1\n",
    "        except:\n",
    "            pass\n",
    "     \n",
    "    return np.asarray(doc_vector) / num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "data['box_vec'] = data.wordbox.apply(doc_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделяем данные, для которых есть вектора.\n",
    "data['help'] = data.box_vec.apply(lambda x: len(x))\n",
    "for_processing = data[data.help>0][['ID_TA','box_vec']]\n",
    "for_processing.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_processing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем матрицу\n",
    "values = []\n",
    "for i in for_processing.box_vec.values:\n",
    "    values.append(i)\n",
    "reshaped = np.array(values)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уменьшаем размерность векторов\n",
    "tsne = TSNE(n_components=2, random_state=RS, verbose=0, learning_rate=100)\n",
    "transformed = tsne.fit_transform(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание кластера\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(transformed)\n",
    "y_pred = kmeans.labels_.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация результата\n",
    "\n",
    "print (\"Коэффициент силуэта: %0.3f\" % silhouette_score(transformed, y_pred, metric='euclidean'))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "plt.scatter(transformed[:, 0], transformed[:, 1], c=y_pred, s=200, alpha=.5)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', s=200, marker='+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент силуэта низок. Так же, визуально, разделение между кластерами весьма условно. Тем не менее, имеет смысл добавить данные. Полезность будет оценена позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление значений во вспомогательный DataFrame\n",
    "for_processing['txt_cluster'] = y_pred+np.ones(y_pred.shape[0])\n",
    "for_processing.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление дубликатов\n",
    "for_processing.drop_duplicates('ID_TA', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление кластера к основным данным\n",
    "data = pd.merge(data,for_processing.drop('box_vec',axis = 1), on='ID_TA', how='outer')\n",
    "data.txt_cluster.fillna(0, inplace=True)\n",
    "\n",
    "# Длинна коментариев\n",
    "data['txt_length'] = data.wordbox.apply(lambda x: len(x))\n",
    "\n",
    "# Удаление вспомогательных признаков\n",
    "data.drop(['wordbox','box_vec','help'], axis=1, inplace=True)\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Обработка ID_TA / URL_TA\n",
    "\n",
    "- В данных имеется ссылка на страницу для каждого ресторана. С одной стороны, актуальные рейтинги могут восприниматься как утечка данных. С другой стороны, ссылки были предоставлены и странно было бы ими не воспользоваться.\n",
    "\n",
    "- Так как, TripAdvisor неохотно предоставляет доступ к API, ссылки были обработаны через HTML запросы к сайту. По скольку, данный процесс занимает довольно много времени, обработка была проведена вне этого ноутбука.\n",
    "\n",
    "- Ссылка на ноутбук обработки:\n",
    "https://github.com/blinnikov-ae/skillfactory_rds/blob/master/module_3/TripAdvisor_actual_rating_april_2021.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка результатов обработки\n",
    "actual_ratings = pd.read_csv('TA_ratings_04_2021.csv')\n",
    "actual_ratings.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на дубликаты\n",
    "actual_ratings.ID_TA.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление кластера к основным данным\n",
    "data = pd.merge(data,actual_ratings, on='ID_TA', how='outer')\n",
    "data.drop('ID_TA', axis=1, inplace=True)\n",
    "\n",
    "# Пометка данных имеющих пропуски\n",
    "data['cur_rate_nan'] = pd.isna(data['current_rating']).astype('uint8')\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог\n",
    "Две текстовые переменные (City, Cuisine Style) могут быть перекодированы в dummy-переменные.  Имеет смысл отдельно проверить полезность Cuisine Style, т.к. переменная очень грамоздкая. Остальные переменные в числовом формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем признаки по группам\n",
    "cat_cols = ['City', 'Price Range','txt_cluster']\n",
    "num_cols = ['Ranking', 'Number of Reviews', 'cuisine_amount', \n",
    "            'rvws_amount', 'rvws_time_span', 'rvws_latest', \n",
    "            'txt_length', 'current_rating']\n",
    "bin_cols = ['cuisine_nan', 'p_range_nan', 'cur_rate_nan']\n",
    "\n",
    "# Проверка, что вошли все колонки, кроме 'train', 'Rating', 'Cuisine Style'\n",
    "len(cat_cols) + len(num_cols) + len(bin_cols) - len(data.columns) + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает среднюю ошибку для данных и модели\n",
    "def MAE(X, y, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = RS)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем данные без признаков с пропусками\n",
    "naive = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "naive = naive.dropna(axis=1)\n",
    "naive.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка категориальных признаков\n",
    "naive = pd.get_dummies(naive, columns = ['City', 'txt_cluster'], prefix=None, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для оценки будем использовать RandomForestRegressor\n",
    "results['naive'] = MAE(X=naive.drop('Rating', axis = 1), \n",
    "    y=naive.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['naive'], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пропуски в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Заполнение нулями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "zeros = zeros.fillna(0)\n",
    "zeros.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка признаков\n",
    "zeros = pd.get_dummies(zeros, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "zeros.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['zeros'] = MAE(X=zeros.drop('Rating', axis = 1), \n",
    "    y=zeros.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['zeros'], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Заполнение медианой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "for col in ['Price Range','Number of Reviews','current_rating']:\n",
    "    median[col].fillna(median[col].median(), inplace=True)\n",
    "median.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка признаков\n",
    "median = pd.get_dummies(median, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "median.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['median'] = MAE(X=median.drop('Rating', axis = 1), \n",
    "    y=median.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['median'], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Заполнение самым частым значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "for col in ['Price Range','Number of Reviews','current_rating']:\n",
    "    frequent[col].fillna(frequent[col].value_counts().index[0], inplace=True)\n",
    "frequent.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка признаков\n",
    "frequent = pd.get_dummies(frequent, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "frequent.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['frequent'] = MAE(X=frequent.drop('Rating', axis = 1), \n",
    "    y=frequent.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['frequent'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.lineplot(x=[x for x in range(len(results.values()))], y=list(results.values()), marker='o')\n",
    "ax.set(ylabel='MAE', xlabel='iter')\n",
    "plt.show()\n",
    "\n",
    "for key, value in results.items():\n",
    "    print('{}: {}'.format(key, np.round(value, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение медианным или самым частым значениями не дают прибавки в точности модели. Это можно объяснить тем, что '0' дополнительно помогает дереву решений отделять примеры с пропусками. В любом случае, не имеет смысл заполнять пропуски по средствам доп. моделирования и можно ограничиться заполнением нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинарные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция, проверяющая наличае статистически значимых различий между вариациями признака\n",
    "def get_stat_dif(df, col, target):\n",
    "    variations=len(df[col].value_counts().index)\n",
    "    indexes=[i for i in range (0,variations)]\n",
    "    comb=list(combinations(indexes, 2))\n",
    "    for c in comb:\n",
    "        x = df[df[col] == df[col].value_counts().index[c[0]]][target]\n",
    "        y = df[df[col] == df[col].value_counts().index[c[1]]][target]\n",
    "        t_test = weightstats.ttest_ind(x, y, usevar='unequal')\n",
    "        if t_test[1] <= 0.05/len(comb):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция выводит основную информацию и график признака\n",
    "def sum_up_cat(df, col, target):\n",
    "    print(col.upper())\n",
    "    vc = df[col].value_counts()\n",
    "    vc_p = df[col].value_counts(normalize=True)\n",
    "    for i in vc.index:\n",
    "        print('{} (%%):\\t{}'.format(i, np.round(vc_p[i],2)))\n",
    "        print('\\t Среднее значение целевой:\\t{}'.format(np.round(df[df[col] == i][target].mean(),2)))\n",
    "    print('Cтатистически значимые различия:\\t{}'.format(get_stat_dif(df, col, target)))\n",
    "    plt.figure()\n",
    "    sns.catplot(data = df,  x = col, kind = 'count', palette = 'viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in bin_cols:\n",
    "    sum_up_cat(data[data.train==1], column, 'Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бинарные признаки отражают пропущенные значения. Признак CUR_RATE_NAN не несет ценности, т.к. статистически значимые различия. Возможно, его стоит удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_CRN = data[data.train==1].drop(['train', 'Restaurant_id', 'cur_rate_nan'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "drop_CRN = pd.get_dummies(drop_CRN, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "drop_CRN.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['drop_CRN'] = MAE(X=drop_CRN.drop('Rating', axis = 1), \n",
    "    y=drop_CRN.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['drop_CRN'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('cur_rate_nan', axis=1, inplace=True)\n",
    "bin_cols.remove('cur_rate_nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Категориальные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cat_cols:\n",
    "    sum_up_cat(data[data.train==1], column, 'Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не смотря на низкий коэффициент силуэта, TXT_CLUSTER представляет ценность. Средний рейтинг ниже для кластеров 2нх из 5. Для CITY статистически значимые различия не найдены. Признак может пригодиться для извлечения доп. данных. Тем не менее, стоит протестировать модель без него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_city = data[data.train==1].drop(['train', 'Restaurant_id', 'City'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "drop_city = pd.get_dummies(drop_city, columns = ['Price Range','txt_cluster'], prefix=None, dummy_na=False)\n",
    "drop_city.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['drop_city'] = MAE(X=drop_city.drop('Rating', axis = 1), \n",
    "    y=drop_city.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['drop_city'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Числовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчитывает кол-во выбросов по столбцам и их долю\n",
    "def outbursts(df, col):\n",
    "    Q25 = df[col].quantile(0.25)\n",
    "    Q75 = df[col].quantile(0.75)\n",
    "    IQR = Q75 - Q25\n",
    "    lowest = Q25 - 1.5*IQR\n",
    "    highest = Q75 + 1.5*IQR\n",
    "    amount = df[(df[col] < lowest)|(df[col] > highest)].count()[0]\n",
    "    ratio = amount/df.shape[0]\n",
    "    return amount, ratio, lowest, highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция выводит основную информацию и график признака\n",
    "def sum_up_num(df, col, target):\n",
    "    print(col.upper())\n",
    "    print(df[col].describe()[1:])\n",
    "    print('Кол-во выбросов: {} \\t (%%: {})'.format(outbursts(df, col)[0], \n",
    "                                                   np.round(outbursts(df, col)[1]*100,2)))\n",
    "    print()\n",
    "    fig, axs = plt.subplots(figsize=(15, 5), ncols=2)\n",
    "    sns.distplot(df[col], kde=True, ax=axs[0])\n",
    "    sns.boxplot(data = df,  x = col, palette = 'viridis', ax=axs[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in num_cols:\n",
    "    sum_up_num(data[data.train==1], column, 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционная матрица\n",
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "sns.heatmap(data[data.train==1][num_cols].corr(), vmin=-1, vmax=1, annot=True, linewidths=.5, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для числовых признаков, имеется довольно много выбросов. Тем не менее, выбросы не выглядят аномальными. Среди признаков, извлеченных из Reviews, наблюдается высокая корреляция. Может иметь смысл избавиться от rvws_latest, как признака для которого выбросы наиболее велики.\n",
    "\n",
    "Так же, необходимо отдельно рассмотреть Ranking, т.к. признак отражает ранг в конкретном городе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_RL = data[data.train==1].drop(['train','Restaurant_id', 'rvws_latest'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "drop_RL = pd.get_dummies(drop_RL, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "drop_RL.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['drop_RL'] = MAE(X=drop_RL.drop('Rating', axis = 1), \n",
    "    y=drop_RL.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['drop_RL'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "for city in data.City.unique()[:5]:\n",
    "    sns.distplot(data[data.City==city]['Ranking'], kde=True, label=city)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без rvws_latest, MAE чуть выше. Имеет смысл стандартизировать Ranking, относительно города. Стандартизация будет выполнена позже, при извлечении доп. информации из City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря с максимальным значением Ranking для города\n",
    "city_max = {}\n",
    "for city in list(data.City.unique()):\n",
    "    city_max[city] = data[data.City == city].Ranking.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возражает произведение значений Ranking и максисального значения Ranking по городу\n",
    "def std_rank(row):\n",
    "    return row.Ranking/city_max[row.City]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр ranking_norm стандартизированный Ranking\n",
    "data['city_ranking'] = data.apply(std_rank, axis = 1)\n",
    "num_cols.append('city_ranking')\n",
    "sum_up_num(data[data.train==1], 'city_ranking', 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционная матрица\n",
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "sns.heatmap(data[data.train==1][num_cols].corr(), vmin=-1, vmax=1, annot=True, linewidths=.5, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_r = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "city_r = pd.get_dummies(city_r, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "city_r.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['city_r'] = MAE(X=city_r.drop('Rating', axis = 1), \n",
    "    y=city_r.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['city_r'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает 'Non_specified' для пустых занчений Cuisine Style\n",
    "def filling_CS_nan(cuisine_style):\n",
    "    if type(cuisine_style) == int:\n",
    "        return ['Non_specified']\n",
    "    else:\n",
    "        return cuisine_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cuisine Style'] = data['Cuisine Style'].apply(filling_CS_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для заполнения категории Cuisine Style\n",
    "def dummy_cuisine(cell):\n",
    "    if item in cell:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список уникальных значений Cuisine Style\n",
    "all_cuisines = pd.Series(data['Cuisine Style'].sum()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cs = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Кодирование Cuisine Style\n",
    "for item in all_cuisines:\n",
    "    dummy_cs[item] = dummy_cs['Cuisine Style'].apply(dummy_cuisine)\n",
    "\n",
    "# Обработка признаков\n",
    "dummy_cs = pd.get_dummies(dummy_cs, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "dummy_cs.drop('Cuisine Style', axis=1, inplace=True)\n",
    "\n",
    "# Расчет метрики\n",
    "results['dummy_cs'] = MAE(X=dummy_cs.drop('Rating', axis = 1), \n",
    "    y=dummy_cs.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['dummy_cs'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление признака Cuisine Style дает лишь несущественное понижение MAE. Можно удалить признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Cuisine Style', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.lineplot(x=[x for x in range(len(results.values()))], y=list(results.values()), marker='o')\n",
    "ax.set(ylabel='MAE', xlabel='iter')\n",
    "plt.show()\n",
    "\n",
    "for key, value in results.items():\n",
    "    print('{}: {}'.format(key, np.round(value, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе анализа данных удалось выявить неинформативный признак. Cтандартизированный Ranking существенно улучшил модель. Cuisine Style был уален."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция измеряет взаимную информацию для ряда переменных\n",
    "def mi_reg(features, target):\n",
    "    mi_scores = mutual_info_regression(features, target, random_state = RS)\n",
    "    mi_scores = pd.Series(mi_scores, index=features.columns)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет взаимной иформации\n",
    "train = data[data.train==1].drop(['train', 'Restaurant_id', 'City'],axis=1)\n",
    "features = train.drop('Rating', axis = 1)\n",
    "target = train.Rating\n",
    "mi_scores = mi_reg(features, target)\n",
    "mi_scores = mi_scores.sort_values()\n",
    "mi_scores.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее информативными признаками являются, созданные при обработке, current_rating, city_ranking. Возможно, имеет смысл дополнительно кластеризировать данные на основе данных признаков.\n",
    "\n",
    "Извлечение данных из Cuisine Style, Reviews и обозначение пропусков не дают ощутимой прибавки в полезной информации. Тем не менее, можно попробовать дополнительно извлечь информацию по городу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация отношения city_ranking и current_rating с учетом целевой Rating\n",
    "sns.lmplot(data=data[data.train==1], \n",
    "                x='current_rating', y='city_ranking',\n",
    "                hue='Rating', palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация\n",
    "x = StandardScaler().fit_transform(data[['current_rating','city_ranking']].values)\n",
    "kmeans.fit(x)\n",
    "y_pred = kmeans.labels_.astype(np.int)\n",
    "\n",
    "print (\"Коэффициент силуэта: %0.3f\" % silhouette_score(x, y_pred, metric='euclidean'))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_pred, s=200, alpha=.5)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', s=200, marker='+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rate_rank_cluster'] = y_pred\n",
    "cat_cols.append('rate_rank_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_cluster = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "rr_cluster = pd.get_dummies(rr_cluster, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "\n",
    "# Расчет метрики\n",
    "results['rr_cluster'] = MAE(X=rr_cluster.drop('Rating', axis = 1), \n",
    "    y=rr_cluster.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['rr_cluster'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация ухудшила модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('rate_rank_cluster', axis=1, inplace=True)\n",
    "cat_cols.remove('rate_rank_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Доп. информация из City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка справочника городов\n",
    "cities_stat = pd.read_csv('worldcities.csv')\n",
    "cities_stat.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка есть ли все города в справочнике.\n",
    "# В случае нескольких городов, взят самый крупный\n",
    "for city in data.City.unique():\n",
    "    cities = cities_stat[cities_stat.city_ascii == city]\n",
    "    if cities.shape[0] == 0:\n",
    "        print('\"{}\" отсутствует в cities_stat'.format(city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oporto одно из двух названий португальского Porto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование Oporto в Porto\n",
    "data['City'] = data['City'].apply(lambda x: 'Porto' if x=='Oporto' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем из справочника только необходимое\n",
    "city_ids = []\n",
    "for city in data.City.unique():\n",
    "    cities = cities_stat[cities_stat.city_ascii == city]\n",
    "    city_id = cities[cities.population == cities.population.max()].index[0]\n",
    "    city_ids.append(city_id)\n",
    "\n",
    "\n",
    "useful_stat = cities_stat.loc[city_ids][['city_ascii','lat','lng','country','population']]\n",
    "useful_stat.rename(columns = {'city_ascii': 'City'}, inplace = True)\n",
    "useful_stat.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление данных\n",
    "data = pd.merge(data,useful_stat, on='City', how='outer')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.append('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "country = pd.get_dummies(country, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "country.drop(['lat','lng','population'],axis=1)\n",
    "\n",
    "# Расчет метрики\n",
    "results['country'] = MAE(X=country.drop('Rating', axis = 1), \n",
    "    y=country.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['country'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак улучшает результат модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Координаты\n",
    "\n",
    "Без использования платного Google API.\n",
    "\n",
    "Карта выгружена с https://www.openstreetmap.org/ по координатам и добавлена как PNG-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Границы координат\n",
    "coor_box = ((data.lng.min(), data.lng.max(), \n",
    "             data.lat.min(), data.lat.max()))\n",
    "coor_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка изображения карты\n",
    "ta_map = plt.imread('tripadvisor_map.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация\n",
    "fig, ax = plt.subplots(figsize = (10,15))\n",
    "ax.scatter(data.lng, data.lat, zorder=1, alpha= 1, c='b', s=20)\n",
    "ax.set_title('Cities')\n",
    "ax.set_xlim(coor_box[0],coor_box[1])\n",
    "ax.set_ylim(coor_box[2],coor_box[3])\n",
    "ax.imshow(ta_map, zorder=0, extent = coor_box, aspect= 'equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация\n",
    "x = data[['lng','lat']].values\n",
    "kmeans.fit(x)\n",
    "y_pred = kmeans.labels_.astype(np.int)\n",
    "\n",
    "print (\"Коэффициент силуэта: %0.3f\" % silhouette_score(x, y_pred, metric='euclidean'))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_pred, s=200, alpha=.5)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', s=200, marker='+')\n",
    "ax.set_xlim(coor_box[0],coor_box[1])\n",
    "ax.set_ylim(coor_box[2],coor_box[3])\n",
    "ax.imshow(ta_map, zorder=0, extent = coor_box, aspect= 'equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добаление к основным данным\n",
    "data['geo_cluster'] = y_pred\n",
    "data.drop(['lat','lng'], axis=1, inplace=True)\n",
    "cat_cols.append('geo_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cluster = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "g_cluster = pd.get_dummies(g_cluster, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "g_cluster.drop(['population'],axis=1)\n",
    "\n",
    "# Расчет метрики\n",
    "results['g_cluster'] = MAE(X=g_cluster.drop('Rating', axis = 1), \n",
    "    y=g_cluster.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['g_cluster'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластериция на регионы Европы не дает прибавки в точности модели. Признак может быть удален."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('geo_cluster', axis=1, inplace=True)\n",
    "cat_cols.remove('geo_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Population\n",
    "\n",
    "Признак на основе населения образован путем деления на ретинг внутри города. Таким образом переменная выше для рестораннов из больших городов с высоким рейтингом. Чтобы распределение выглядело информативно, данные логорифмированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pop2rank'] = np.log(data['population']/data['Ranking'])\n",
    "num_cols.append('pop2rank')\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up_num(data[data.train==1], 'pop2rank', 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционная матрица\n",
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "sns.heatmap(data[data.train==1][num_cols].corr(), vmin=-1, vmax=1, annot=True, linewidths=.5, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2rank = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Обработка признаков\n",
    "pop2rank = pd.get_dummies(pop2rank, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "\n",
    "# Расчет метрики\n",
    "results['pop2rank'] = MAE(X=pop2rank.drop('Rating', axis = 1), \n",
    "    y=pop2rank.Rating, model=RandomForestRegressor(random_state=RS))\n",
    "print('MAE:\\t',np.round(results['pop2rank'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переменая не улучшила результат и подлежит удалению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('pop2rank', axis=1, inplace=True)\n",
    "num_cols.remove('pop2rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.lineplot(x=[x for x in range(len(results.values()))], y=list(results.values()), marker='o')\n",
    "ax.set(ylabel='MAE', xlabel='iter')\n",
    "plt.show()\n",
    "\n",
    "for key, value in results.items():\n",
    "    print('{}: {}'.format(key, np.round(value, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из 4 протестированных переменных, только страна ресторана улучшила MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будут протестированы два ансабля моделей:\n",
    "- Для случайного леса будут подобраны оптимальные параметры.\n",
    "- Альтернативой будет градиентный бустинг.\n",
    "\n",
    "GridSearch для ансаблей требует больших ресурсов. По этой причине, подбор оптиальных параметров производился вручную в отдельном ноутбуке без кросс-валидации.\n",
    "\n",
    "Ссылка на ноутбук: https://github.com/blinnikov-ae/skillfactory_rds/blob/master/module_3/TripAdvisor_model_selection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка признаков\n",
    "data = pd.get_dummies(data, columns = cat_cols, prefix=None, dummy_na=False)\n",
    "\n",
    "model_selection = data[data.train==1].drop(['train','Restaurant_id'],axis=1)\n",
    "\n",
    "# Разбиение выборки\n",
    "X = model_selection.drop('Rating', axis = 1)\n",
    "y = model_selection.Rating\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor(random_state=RS, n_estimators=1000)\n",
    "\n",
    "RF.fit(X_train, y_train)\n",
    "RF_y_pred = RF.predict(X_test)\n",
    "    \n",
    "results['rf_model'] = mean_absolute_error(y_test, RF_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingRegressor(random_state=RS, max_depth=10, n_estimators=58)\n",
    "\n",
    "GB.fit(X_train, y_train)\n",
    "GB_y_pred = GB.predict(X_test)\n",
    "    \n",
    "results['gb_model'] = mean_absolute_error(y_test, GB_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.lineplot(x=[x for x in range(len(results.values()))], y=list(results.values()), marker='o')\n",
    "ax.set(ylabel='MAE', xlabel='iter')\n",
    "plt.show()\n",
    "\n",
    "for key, value in results.items():\n",
    "    print('{}: {}'.format(key, np.round(value, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе модели показывают примерно одинаковый результат. RandomForest показывает себя чуть лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка результатов моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращяет результат модели приведенный к формату целевой переменной\n",
    "def adjusted(y_pred):\n",
    "    return np.round(y_pred*2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE для обработоного результа RandomForest\n",
    "results['rf_adj'] = mean_absolute_error(y_test, adjusted(RF_y_pred))\n",
    "print('MAE:\\t',np.round(results['rf_adj'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE для обработоного результа GradientBoosting\n",
    "results['gb_adj'] = mean_absolute_error(y_test, adjusted(GB_y_pred))\n",
    "print('MAE:\\t',np.round(results['gb_adj'],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обработанных результатов, GradientBoosting чуть точнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разница значений\n",
    "np.unique(np.absolute(adjusted(RF_y_pred)-adjusted(GB_y_pred)), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания отличаются для около 500та случаев. Можно попробовать улучшить результат, усреднив результаты двух моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['combined'] = mean_absolute_error(y_test, np.round(adjusted(RF_y_pred)+adjusted(GB_y_pred))/2)\n",
    "print('MAE:\\t',np.round(results['combined'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка, что результаты не выбиваются из возможных пределов\n",
    "np.unique(np.round(adjusted(RF_y_pred)+adjusted(GB_y_pred))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.lineplot(x=[x for x in range(len(results.values()))], y=list(results.values()), marker='o')\n",
    "ax.set(ylabel='MAE', xlabel='iter')\n",
    "plt.show()\n",
    "\n",
    "for key, value in results.items():\n",
    "    print('{}: {}'.format(key, np.round(value, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка результатов моделирование дала существенное снижение MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формат ответа\n",
    "sample_submission.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка размерности\n",
    "print(sample_submission.shape)\n",
    "print(data[data.train==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка\n",
    "submission = data[data.train==0].drop(['train'],axis=1)\n",
    "rest_id = submission.Restaurant_id\n",
    "submission = submission.drop(['Restaurant_id'],axis=1)\n",
    "\n",
    "# Предсказание\n",
    "X_valid = submission.drop('Rating', axis = 1)\n",
    "predictions = np.round(adjusted(RF.predict(X_valid))+adjusted(GB.predict(X_valid)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись\n",
    "sample_submission['Restaurant_id'] = rest_id.values\n",
    "sample_submission['Rating'] = predictions\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
