{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "from datetime import datetime, timedelta \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"example app\")\n",
    "import pycountry\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первичный анализ DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(data.columns):\n",
    "    display(len(data[i].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как уникальных значений ID_TA и URL_TA меньше 50,000, данные могут содержать дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание DF содежащего дубликаты по признаку ID_TA\n",
    "duplicates=data[data.ID_TA.duplicated() == True].sort_values(by ='ID_TA')\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.City.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по всему, данные задвоеннны по City == Madrid|City == Warsaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_check = []\n",
    "for i in list(duplicates.ID_TA):\n",
    "    # Ниже вычисление разницы в целевой переменной для дубликатов\n",
    "    dif = list(data[data.ID_TA == i].Rating)[0] - list(data[data.ID_TA == i].Rating)[1]\n",
    "    difference_check.append(dif)\n",
    "difference_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница в целевой переменной между дублями варируется в том же диапазоне, что и переменная в срезе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.ID_TA == duplicates.ID_TA.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.ID_TA == duplicates.ID_TA.iloc[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по всему, разница между некоторыми дублями объясняется тем, что они распределены между файлами kaggle_task и main_task.\n",
    "\n",
    "Имеет смысл создать переменную, которая обозначит, что у строки есть дубль"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Отметка дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Помечаем новыми пизнаками превые и последние дубликаты\n",
    "data['1'] = data.ID_TA.duplicated(keep='first')\n",
    "data['2'] = data.ID_TA.duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обрабатывает всмогательные столюцы и возвращает 1 для строк имеющих дубли\n",
    "def duplicate(row):\n",
    "    result = 0\n",
    "    if row['1'] == True:\n",
    "        result = 1\n",
    "    elif row['2'] == True:\n",
    "        result = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "data['has_duplicate'] = data.apply(duplicate, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление вспомогательных столбцов\n",
    "data.drop(['1','2'], axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data \n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ, преобразование и заполнение признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Предположительные сети ресторанов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание серии содержащей ID и кол-во ресторанов\n",
    "id_vc = data.groupby(['Restaurant_id']).Ranking.count()\n",
    "id_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление полученной информации в DF\n",
    "data['id_amount'] = data.Restaurant_id.apply(lambda x: id_vc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"id_amount\", y=\"Rating\",\n",
    "                sizes=(1, 8), linewidth=0,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для крупных сетей ниже разброс ненулевых значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Преобразование и заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пометка данных имеющих пропуски\n",
    "data['price_class_nan'] = pd.isna(data['Price Range']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание словоря для преобразования класса цены в число, где 1 - самые дешевые рестораны.\n",
    "mapping_dict = {data['Price Range'].unique()[0]: 2,\n",
    "                data['Price Range'].unique()[2]: 3,\n",
    "                data['Price Range'].unique()[3]: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование признака в числовой формат для работы с пропусками\n",
    "data['price_class'] = data['Price Range'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вычисления среднего класса по городу и квинтилю Ranking для города\n",
    "def main_price(city, i):\n",
    "    data_c = data[data.City == city]\n",
    "    result = data_c[(data_c.Ranking.quantile(i) <= data_c.Ranking) & (data_c.Ranking < data_c.Ranking.quantile(i+0.2))].price_class.dropna().mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вычисляющая скрию значений по городам для определенного квинтиля\n",
    "def quantile(quantile):\n",
    "    series=[]\n",
    "    for i in data.City.unique():\n",
    "        series.append(main_price(i, quantile))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DF c итоговыми значениями\n",
    "city_price = pd.DataFrame({'city': data.City.unique()})\n",
    "quantiles = [x/10 for x in range(8, -1, -2)]\n",
    "for i in quantiles:\n",
    "    city_price[i]=quantile(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев, среднеарифметический класс соответствует самому популярному значению в DF (средний). Тем не менее, иммется ряд исключений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание списка содержащего вложенный список [город-квинтиль],\n",
    "#где преоблядают дешевые рестораны.\n",
    "class1_price=[]\n",
    "for i in quantiles:\n",
    "    for j in city_price[city_price[i]<1.5].city:\n",
    "        class1_price.append([j, i])\n",
    "class1_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполнение соответствующих значений\n",
    "class1_indexes=[]\n",
    "if len(class1_price)>0:\n",
    "    #Цикл достает индексы строк соответствующих парам [город-квинтиль]\n",
    "    for pair in class1_price:\n",
    "        city = pair[0]\n",
    "        Q = pair[1]\n",
    "        df = data[(data.City == city) & (data[data.City == city].Ranking.quantile(Q) <= data.Ranking) & (data[data.City == city].Ranking < data.Ranking.quantile(Q+0.2))]\n",
    "        #Цикл оставляет только пустые ячейки\n",
    "        for i in df[df.price_class.isna()].index:\n",
    "            class1_indexes.append(i)\n",
    "    #Цикл заполния пустых значений\n",
    "    for i in class1_indexes:\n",
    "        data.xs(i)['price_class'] = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание списка содержащего вложенный список [город-квинтиль], где преоблядают дорогие рестораны.\n",
    "#Не сотря на то, что список пуст, он может быть актуален для других данных\n",
    "class3_price=[]\n",
    "for i in quantiles:\n",
    "    for j in city_price[city_price[i]>=2.5].city:\n",
    "        class1_price.append([j, i])\n",
    "class3_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполнение соответствующих значений аналогично дешевым ресторанам\n",
    "class3_indexes=[]\n",
    "if len(class3_price)>0:\n",
    "    for pair in class3_price:\n",
    "        city = pair[0]\n",
    "        Q = pair[1]\n",
    "        df = data[(data.City == city) & (data[data.City == city].Ranking.quantile(Q) <= data.Ranking) & (data[data.City == city].Ranking < data.Ranking.quantile(Q+0.2))]\n",
    "        for i in df[df.price_class.isna()].index:\n",
    "            class3_indexes.append(i)\n",
    "    for i in class3_indexes:\n",
    "        data.xs(i)['price_class'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполнение оставшихся ячеек самым популярным значением\n",
    "data.price_class.fillna(value = 2, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_class'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='price_class', y='Rating',\n",
    "            kind=\"violin\", bw=.1, cut=0,\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Преобразование и заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пометка данных имеющих пропуски\n",
    "data['cuisine_nan'] = pd.isna(data['Cuisine Style']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание списка из строки\n",
    "data['Cuisine Style'] = data['Cuisine Style'].str.findall(r'\\w+\\s*\\w*\\s*\\w*\\s*\\w*\\s*\\w*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция вычисляющая самую популярную кухню в городе.\n",
    "#Значение \"European\" опущено, т.к. говорит о географическом происхождении не достаточно точно\n",
    "def popular_cuisine(city):\n",
    "    popular_values = pd.Series(data[data.City == city]['Cuisine Style'].dropna().sum()).value_counts()\n",
    "    if popular_values.index[0] != 'European':\n",
    "        result = popular_values.index[0]\n",
    "    else:\n",
    "        result = popular_values.index[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание вспомогательного DF для более быстрого заполнения пропусков\n",
    "city_cuisine = pd.DataFrame({'city': data.City.unique()})\n",
    "city_cuisine['cuisine'] = city_cuisine.city.apply(popular_cuisine)\n",
    "city_cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция заполнения пропусков популярным значением для города\n",
    "def associated_cuisine(city):\n",
    "    result = city_cuisine[city_cuisine.city == city].iloc[0][1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция преобразования заполненных строк в список\n",
    "def making_list(cell):\n",
    "    if type(cell) == list:\n",
    "        result = cell\n",
    "    elif type(cell) == str:\n",
    "        result = re.findall(r'\\w+\\s*\\w*\\s*\\w*\\s*\\w*\\s*\\w*', cell)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Применение вышеописанных функций + создание столбца кол-ва кухонь\n",
    "data['Cuisine Style'].fillna(value=data.City.apply(associated_cuisine), inplace=True)\n",
    "data['Cuisine Style'] = data['Cuisine Style'].apply(making_list)\n",
    "data['cuisine_amount'] = data['Cuisine Style'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Преобразование и создание доп. парметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропусков всего 2, можно заполнить самым популярным(пустым списом) значением\n",
    "data.Reviews.fillna(data.Reviews.value_counts().index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция преобразоватия строковой даты в формат datetime\n",
    "def date_conversion(cell):\n",
    "    resulting_list=[]\n",
    "    for i in cell:\n",
    "        if int(i[:i.find('/')])<=12:\n",
    "            converted_time = datetime.strptime(i, '%m/%d/%Y')\n",
    "            resulting_list.append(converted_time)\n",
    "        else:\n",
    "            if '/' in i[-4:]:\n",
    "                converted_time = datetime.strptime(i, '%d/%m/%y')\n",
    "                resulting_list.append(converted_time)\n",
    "            else:\n",
    "                converted_time = datetime.strptime(i, '%d/%m/%Y')\n",
    "                resulting_list.append(converted_time)\n",
    "    return resulting_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание параметра review_dates содержащего список дат отзывов\n",
    "data['review_dates'] = data.Reviews.str.findall(r'\\d+/\\d+/\\d+')\n",
    "data.review_dates = data.review_dates.dropna().apply(date_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фунция вычисляет разницу между превым и последним отзывом\n",
    "def review_t_dif(cell):\n",
    "    if len(cell)>=2:\n",
    "        dif=max(cell)-min(cell)\n",
    "    else:\n",
    "        dif=timedelta(days = 0)\n",
    "    return dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр review_time_span отбражает разницу между превым и последним отзывом\n",
    "data['review_time_span'] = data.review_dates.dropna().apply(review_t_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Перевод результата в секунды\n",
    "data.review_time_span = data.review_time_span.apply(lambda x: x.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр visible_reviews отбражает кол-во видимых отзывов\n",
    "data['visible_reviews'] = data.review_dates.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='review_time_span', y='Rating',\n",
    "                sizes=(1, 8), linewidth=0,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['visible_reviews'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='visible_reviews', y='Rating',\n",
    "            kind=\"violin\", bw=.1, cut=0,\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Применение списков ключевых слов для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр review_wordbox включает список слов используемых в Reviews\n",
    "data.Reviews = data.Reviews.apply(lambda x: x.lower())\n",
    "data['review_wordbox'] = data.Reviews.str.findall(r'\\w[a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все слова, встречающиеся более 2 раз у ресторанов с целевой переменной от 4.5\n",
    "wordbox_positive = pd.Series(data[(data['sample'] == 1)&(data.Rating>=4.5)].review_wordbox.sum())\n",
    "p_words = pd.DataFrame(wordbox_positive.value_counts())\n",
    "p_words = p_words[p_words[0]>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все слова, встречающиеся более 2 раз у ресторанов с целевой переменной до 3.5\n",
    "wordbox_negative = pd.Series(data[(data['sample'] == 1)&(data.Rating<=3.5)].review_wordbox.sum())\n",
    "n_words = pd.DataFrame(wordbox_negative.value_counts())\n",
    "n_words = n_words[n_words[0]>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слова, уникальные для ресторанов с высоким рейтингом\n",
    "positive_review_predictors = []\n",
    "for i in p_words.index:\n",
    "    if i not in list(n_words.index):\n",
    "        positive_review_predictors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слова, уникальные для ресторанов с низким рейтингом\n",
    "negative_review_predictors = []\n",
    "for i in n_words.index:\n",
    "    if i not in list(p_words.index):\n",
    "        negative_review_predictors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчитывающая рейтинг по ключевым словам. Нейтральное значение = 0.5\n",
    "def valued_review_score(wordbox):\n",
    "    positives = 1\n",
    "    negatives = 1\n",
    "    for i in wordbox:\n",
    "        if i in positive_review_predictors:\n",
    "            positives += 1\n",
    "        elif i in negative_review_predictors:\n",
    "            negatives += 1\n",
    "    result = positives/(positives + negatives)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр valued_review содержит условный рейтинг, расчитаный на осонове слов, содежащихся в Reviews\n",
    "data['valued_review'] = data.review_wordbox.apply(valued_review_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='valued_review', y='Rating',\n",
    "                sizes=(1, 8), linewidth=0,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пометка данных имеющих пропуски\n",
    "data['NoF_nan'] = pd.isna(data['Number of Reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вычисления среднего класса по городу и квинтилю Ranking для города\n",
    "def avg_reviews(city, i):\n",
    "    data_c = data[data.City == city]\n",
    "    result = data_c[(data_c.Ranking.quantile(i) <= data_c.Ranking) & (data_c.Ranking < data_c.Ranking.quantile(i+0.2))]['Number of Reviews'].dropna().mean()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция вычисляющая серию значений по городам для определенного квинтиля\n",
    "def quantile(quantile):\n",
    "    series=[]\n",
    "    for i in data.City.unique():\n",
    "        series.append(avg_reviews(i, quantile))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DF c итоговыми значениями\n",
    "city_rev = pd.DataFrame({'city': data.City.unique()})\n",
    "quantiles = [x/10 for x in range(8, -1, -2)]\n",
    "for i in quantiles:\n",
    "    city_rev[i]=quantile(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает соответсвующее значение из city_rev по City и Ranking\n",
    "def aprx_rev_amount(x):\n",
    "    d = data[data.City == x['City']]\n",
    "    quantiles = [n/10 for n in range(8, -1, -2)]\n",
    "    for i in quantiles:\n",
    "        if d.Ranking.quantile(i) <= x['Ranking'] <= d.Ranking.quantile(i+0.2):\n",
    "            result = float(int(city_rev[city_rev.city == x['City']][i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание серии, содержащей индексы пустых значений с соответствующее значение из city_rev\n",
    "# fillna() не ипользовал, т.к. рачеты занимали больше времени\n",
    "reviews_for_nan = data[data['Number of Reviews'].isna() == True].apply(aprx_rev_amount, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнение пропусков в основном DF\n",
    "for i in list(reviews_for_nan.index):\n",
    "    data['Number of Reviews'].loc[i] = reviews_for_nan[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Нормолизация в зависимости от City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря, содержащего пары город: длинна вектора Ranking по городу\n",
    "v_lengths = {}\n",
    "for i in list(data.City.unique()):\n",
    "    v_lengths[i] = np.linalg.norm(data[data.City == i].Ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возражает произведение значения Ranking и длинны вектора Ranking по городу\n",
    "def normalization(row):\n",
    "    result = row.Ranking/v_lengths[row.City]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр ranking_norm содержит нормализованный Ranking\n",
    "data['ranking_norm'] = data.apply(normalization, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='ranking_norm', y='Rating',\n",
    "                sizes=(1, 8), linewidth=0,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Создание доп. параметров на основе City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание списка уникальных значений City\n",
    "city_state = pd.DataFrame({'city': data.City.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает код страны по названию города\n",
    "def country(city):\n",
    "    coordinates = geolocator.geocode(city)[1]\n",
    "    location = geolocator.reverse(coordinates, exactly_one=True)\n",
    "    address = location.raw['address']\n",
    "    country = address.get('country_code', '')\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает население по названию города и коду страны \n",
    "def city_population(row):\n",
    "    city = row.city\n",
    "    country = row.country\n",
    "    tmp = 'https://public.opendatasoft.com/api/records/1.0/search/?dataset=worldcitiespop&q=%s&sort=population&facet=country&refine.country=%s'\n",
    "    cmd = tmp % (city, country)\n",
    "    res = requests.get(cmd)\n",
    "    dct = json.loads(res.content)\n",
    "    info = dct['records'][0]['fields']\n",
    "    if 'population' in info.keys():\n",
    "        result = info['population']\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функций, перевод кода страны в верхгий регистр, замена на название страны по коду\n",
    "city_state['country'] = city_state.city.apply(country)\n",
    "city_state['population'] = city_state.apply(city_population, axis = 1)\n",
    "city_state.country = city_state.country.apply(lambda x: x.upper())\n",
    "city_state.country = city_state.country.apply(lambda x: pycountry.countries.get(alpha_2=x).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список с GIT, содержащий пары страна, прилагательное\n",
    "demonyms = pd.read_csv('/kaggle/input/country-adjective-pairs/demonyms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает список прилагательных соответствующих стране\n",
    "# Если функция возващает пустой список, сокращенное название страны меняется на официальное\n",
    "def adjectives(country):\n",
    "    result = list(demonyms[demonyms.Aalborg == country].Aalborgenser)\n",
    "    if len(result) == 0:\n",
    "        alternative = pycountry.countries.get(name=country).official_name\n",
    "        result = list(demonyms[demonyms.Aalborg == alternative].Aalborgenser)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "city_state['adjectives'] = city_state.country.apply(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция заполняет параметр native_cuisine.\n",
    "# ==1, если один из тегов Cuisine Style совпадает с прилагательными города\n",
    "def native(row):\n",
    "    result = 0\n",
    "    for i in city_state[city_state.city == row.City].adjectives.sum():\n",
    "        if i in row['Cuisine Style']:\n",
    "            result = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметр native_cuisine отбражает евляется ли кухня национальной\n",
    "data['native_cuisine'] = data.apply(native, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание словоря с парами город - население\n",
    "mapping_population = {}\n",
    "for i in city_state.index:\n",
    "    mapping_population[city_state.city[i]]=city_state.population[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление населения\n",
    "# Создания параметра отнашения населения и ранка ресторана.\n",
    "# Таким образом, наибольшим значением обладают высокоранговые рестораны в больших городах\n",
    "data['city_population'] = data.City.map(mapping_population)\n",
    "data['feature_1']=data['city_population']/data['Ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['native_cuisine'].hist(bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='native_cuisine', y='Rating',\n",
    "            kind=\"violin\", bw=.1, cut=0,\n",
    "            data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city_population'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='feature_1', y='Rating',\n",
    "                sizes=(1, 8), linewidth=0,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Промежуточный итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.corr()\n",
    "ax = plt.subplots(figsize=(15, 15))\n",
    "sns.heatmap(correlation, annot=True, cmap='vlag', linewidths=1, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dummy-variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/mtimFxh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем сетку\n",
    "data = pd.get_dummies(data, columns=[ 'City'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для заполнения категории Cuisine Style\n",
    "def dummy_cuisine(cell):\n",
    "    if item in cell:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список уникальных значений переменной\n",
    "all_cuisines = pd.Series(data['Cuisine Style'].sum()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "for item in all_cuisines:\n",
    "    data[item] = data['Cuisine Style'].apply(dummy_cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем сетку\n",
    "data = pd.get_dummies(data, columns=[ 'price_class'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Предобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не стал писать футкцию для предобработки, т.к. задействованно достаточно много сторонних источников и вспомогательных таблиц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очистка от строк/списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = [s for s in data.columns if data[s].dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(object_columns, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = data\n",
    "df_preproc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
